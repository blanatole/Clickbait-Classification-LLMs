# Data Configuration for Webis-Clickbait-17 Dataset

# Dataset paths
data:
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  splits_dir: "data/splits"
  
  # Original dataset files
  train_instances: "data/clickbait17-validation-170630/instances.jsonl"
  train_truth: "data/clickbait17-validation-170630/truth.jsonl"
  test_instances: "data/clickbait17-test-170720/instances.jsonl"
  test_truth: "data/clickbait17-test-170720/truth.jsonl"

# Data processing parameters
processing:
  # Text fields to extract and use
  text_fields:
    - "postText"
    - "targetTitle"
    - "targetDescription"
    - "targetParagraphs"
    - "targetKeywords"
  
  # Primary text field for training (as recommended in README)
  primary_text_field: "postText"
  
  # Label conversion
  label_conversion:
    # Convert truthMean to binary using threshold
    threshold: 0.5  # >= 0.5 = clickbait, < 0.5 = no-clickbait
    
    # Label mapping
    clickbait_label: 1
    no_clickbait_label: 0

# Data splitting (stratified split as recommended)
splits:
  train_size: 0.7      # 70% for training
  validation_size: 0.2 # 20% for validation
  test_size: 0.1       # 10% for final test
  
  # Stratification
  stratify: true
  random_state: 42

# Text cleaning configuration (specialized for social media)
text_cleaning:
  # URL handling
  remove_urls: true
  remove_short_urls: true  # bit.ly, t.co, etc.
  
  # Social media specific
  remove_mentions: true    # @username
  process_hashtags: true
  keep_hashtag_text: true  # Keep text content of hashtags
  
  # Contact information
  remove_emails: true
  remove_phone_numbers: true
  
  # Emoji handling
  emoji_strategy: "remove"  # Options: remove, keep, replace
  
  # Text normalization
  to_lowercase: true
  normalize_repetitive_chars: true
  max_char_repeat: 2  # "sooooo" -> "soo"
  
  # Special characters
  keep_punctuation: true
  remove_special_chars: true
  
  # Whitespace normalization
  normalize_whitespace: true

# Class imbalance handling (as noted in README: ~1:3 ratio)
class_balance:
  strategy: "weighted"  # Options: oversample, undersample, weighted, none
  
  # For oversampling
  oversample_method: "SMOTE"
  
  # For undersampling  
  undersample_method: "RandomUnderSampler"
  
  # For weighted approach
  class_weight: "balanced"  # Automatically calculate weights

# Data validation
validation:
  check_missing_values: true
  check_text_length: true
  min_text_length: 5      # Minimum characters
  max_text_length: 1000   # Maximum characters for primary field
  
  # Quality checks
  check_duplicate_ids: true
  check_label_distribution: true 