# HÆ°á»›ng Dáº«n Triá»ƒn Khai: Khai thÃ¡c LLM Ä‘á»ƒ PhÃ¡t hiá»‡n Clickbait

## ğŸ“‹ Tá»•ng Quan Dá»± Ãn

Dá»± Ã¡n nÃ y thá»±c hiá»‡n viá»‡c **khai thÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) Ä‘á»ƒ phÃ¡t hiá»‡n clickbait** trÃªn táº­p dá»¯ liá»‡u **Webis-Clickbait-17** thÃ´ng qua hai phÆ°Æ¡ng phÃ¡p chÃ­nh:

1. **Fine-tuning**: Tinh chá»‰nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»›i PEFT/LoRA vÃ  Unsloth
2. **Prompting**: Sá»­ dá»¥ng cÃ¡c LLM ná»n táº£ng thÃ´ng qua gá»£i Ã½ (zero-shot vÃ  few-shot)

## ğŸ—ï¸ Kiáº¿n TrÃºc Dá»± Ãn

```
clickbait-classification/
â”œâ”€â”€ ğŸ“ src/                           # Source code chÃ­nh
â”‚   â”œâ”€â”€ data_processing/              # Xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ fine_tuning/                  # Fine-tuning approach
â”‚   â”œâ”€â”€ prompting/                    # Prompting approach
â”‚   â”œâ”€â”€ utils/                        # Utilities chung
â”‚   â””â”€â”€ comparison/                   # So sÃ¡nh káº¿t quáº£
â”œâ”€â”€ ğŸ“ configs/                       # Configuration files
â”œâ”€â”€ ğŸ“ scripts/                       # Scripts cháº¡y pipeline
â”œâ”€â”€ ğŸ“ notebooks/                     # Jupyter notebooks
â”œâ”€â”€ ğŸ“ data/                          # Dá»¯ liá»‡u
â”œâ”€â”€ ğŸ“ models/                        # Models Ä‘Ã£ fine-tuned
â”œâ”€â”€ ğŸ“ experiments/                   # Káº¿t quáº£ thÃ­ nghiá»‡m
â””â”€â”€ ğŸ“ outputs/                       # Outputs vÃ  logs
```

## ğŸš€ HÆ°á»›ng Dáº«n CÃ i Äáº·t

### BÆ°á»›c 1: Clone vÃ  Setup MÃ´i TrÆ°á»ng

```bash
# Clone repository (náº¿u cÃ³)
git clone <repository-url>
cd clickbait-classification

# Cháº¡y script setup
python scripts/setup_project.py
```

### BÆ°á»›c 2: CÃ i Äáº·t Dependencies

#### TrÃªn Windows:
```cmd
install.bat
```

#### TrÃªn Linux/MacOS:
```bash
./install.sh
```

#### CÃ i Ä‘áº·t thá»§ cÃ´ng:
```bash
# Táº¡o virtual environment
python -m venv clickbait_env

# KÃ­ch hoáº¡t environment
# Windows:
clickbait_env\Scripts\activate
# Linux/MacOS:
source clickbait_env/bin/activate

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### BÆ°á»›c 3: Cáº¥u HÃ¬nh API Keys

```bash
# Copy template vÃ  cáº¥u hÃ¬nh API keys
cp .env.template .env

# Chá»‰nh sá»­a .env vá»›i API keys thá»±c:
# OPENAI_API_KEY=your_actual_key
# ANTHROPIC_API_KEY=your_actual_key
# HUGGINGFACE_API_KEY=your_actual_key
```

## ğŸ“Š Pipeline Xá»­ LÃ½ Dá»¯ Liá»‡u

### BÆ°á»›c 1: Xá»­ LÃ½ Dá»¯ Liá»‡u

```bash
# Cháº¡y pipeline xá»­ lÃ½ dá»¯ liá»‡u hoÃ n chá»‰nh
python scripts/run_data_processing.py
```

**QuÃ¡ trÃ¬nh bao gá»“m:**
- âœ… Load dá»¯ liá»‡u tá»« JSONL files
- âœ… TrÃ­ch xuáº¥t text features, loáº¡i bá» media components  
- âœ… LÃ m sáº¡ch vÄƒn báº£n chuyÃªn biá»‡t cho social media:
  - Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng
  - Loáº¡i bá» URLs, mentions (@username)
  - Xá»­ lÃ½ hashtags (giá»¯ láº¡i text content)
  - Chuáº©n hÃ³a kÃ½ tá»± láº·p vÃ  whitespace
- âœ… Chuyá»ƒn Ä‘á»•i labels tá»« truthMean â†’ binary (>= 0.5 = clickbait)
- âœ… Chia dá»¯ liá»‡u train/val/test vá»›i stratification
- âœ… Xá»­ lÃ½ class imbalance (~1:3 ratio)

## ğŸ”§ Approach 1: Fine-tuning

### MÃ´ HÃ¬nh ÄÆ°á»£c Há»— Trá»£

1. **RoBERTa-base** (baseline - Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ trÃªn Webis-Clickbait-17)
2. **Mistral-7B** (modern approach vá»›i PEFT/LoRA)  
3. **LLaMA-3-8B** (vá»›i Unsloth optimization)

### Cháº¡y Fine-tuning

```bash
# RoBERTa baseline
python scripts/run_fine_tuning.py --model roberta

# Mistral vá»›i PEFT/LoRA
python scripts/run_fine_tuning.py --model mistral --use-peft

# LLaMA vá»›i Unsloth
python scripts/run_fine_tuning.py --model llama --use-peft --use-unsloth
```

### Ká»¹ Thuáº­t Optimization

- **PEFT/LoRA**: Chá»‰ fine-tune <1% parameters
- **Unsloth**: TÄƒng tá»‘c 2x, giáº£m 60% memory cho Mistral/LLaMA
- **Quantization**: 4-bit loading vá»›i bitsandbytes
- **Gradient Checkpointing**: Tiáº¿t kiá»‡m memory

## ğŸ¯ Approach 2: Prompting

### Zero-shot Prompting

```bash
# GPT-4 zero-shot
python scripts/run_prompting.py --model gpt4 --strategy zero_shot --sample-size 1000

# Claude-3 zero-shot  
python scripts/run_prompting.py --model claude3 --strategy zero_shot --sample-size 1000
```

### Few-shot Prompting

```bash
# GPT-4 few-shot vá»›i 5 examples
python scripts/run_prompting.py --model gpt4 --strategy few_shot --sample-size 1000

# GPT-4o few-shot
python scripts/run_prompting.py --model gpt4o --strategy few_shot --sample-size 1000
```

### MÃ´ HÃ¬nh ÄÆ°á»£c Há»— Trá»£

- **OpenAI**: GPT-4, GPT-4-turbo, GPT-4o
- **Anthropic**: Claude-3-Sonnet, Claude-3-Opus
- **Open-source**: Mixtral, LLaMA via HuggingFace API

## ğŸ“ˆ ÄÃ¡nh GiÃ¡ vÃ  So SÃ¡nh

### Metrics Theo DÃµi

- **Accuracy**, **Precision**, **Recall**, **F1-score**
- **Confusion Matrix** cho phÃ¢n tÃ­ch lá»—i chi tiáº¿t
- **Cost Analysis** cho prompting approach
- **Speed Benchmarking** cho cáº£ hai approaches

### Benchmark Targets

| Method | Accuracy | F1-score | Source |
|--------|----------|----------|---------|
| Clickbait Challenge 2017 Winner | 0.876 | 0.741 | Official |
| RoBERTa (Prior Work) | 0.8575 | 0.6901 | Research |
| **Target for This Project** | **> 0.85** | **> 0.70** | Goal |

### Cháº¡y So SÃ¡nh ToÃ n Diá»‡n

```bash
# So sÃ¡nh táº¥t cáº£ approaches
python scripts/run_comparison.py

# Táº¡o bÃ¡o cÃ¡o cuá»‘i cÃ¹ng
python scripts/generate_final_report.py
```

## ğŸ’° Chiáº¿n LÆ°á»£c Triá»ƒn Khai (theo README)

### Giai Ä‘oáº¡n 1: Prototyping
- Sá»­ dá»¥ng **Prompting** vá»›i GPT-4o
- Má»¥c Ä‘Ã­ch: Proof of Concept nhanh chÃ³ng
- Chi phÃ­ tháº¥p, validation Ã½ tÆ°á»Ÿng

### Giai Ä‘oáº¡n 2: Production
- Chuyá»ƒn sang **Fine-tuning** 
- Stack Ä‘á» xuáº¥t: **Mistral-7B + PEFT/LoRA + Unsloth**
- Má»¥c Ä‘Ã­ch: Hiá»‡u quáº£ chi phÃ­, tá»‘c Ä‘á»™ suy luáº­n nhanh, quyá»n riÃªng tÆ°

## ğŸ–¥ï¸ YÃªu Cáº§u Pháº§n Cá»©ng

### Cho Fine-tuning (Khuyáº¿n nghá»‹)

- **GPU**: NVIDIA A5000 (24GB VRAM) - Ä‘á»ƒ thuÃª khi ready
- **RAM**: 32GB+
- **Storage**: 100GB+ free space

### Cho Development (Hiá»‡n táº¡i)

- **CPU**: Xá»­ lÃ½ dá»¯ liá»‡u vÃ  prompting
- **RAM**: 16GB+
- **Storage**: 50GB+

### Cloud Alternatives

- **Google Colab Pro/Pro+** 
- **Paperspace Gradient**
- **AWS/GCP GPU instances**

## ğŸ“ Configuration Management

### Data Configuration (`configs/data_config.yaml`)
- Text fields selection
- Cleaning parameters 
- Label conversion settings
- Class imbalance handling

### Model Configuration (`configs/model_config.yaml`)
- Model selections
- Quantization settings
- Memory optimization
- Tokenization parameters

### Training Configuration (`configs/training_config.yaml`)
- Hyperparameters
- PEFT/LoRA settings
- Hardware-specific configs
- Logging and monitoring

### API Configuration (`configs/api_config.yaml`)
- Provider settings
- Prompt templates
- Rate limiting
- Cost tracking

## ğŸ” Monitoring vÃ  Logging

### Experiment Tracking
- **Structured logging** cho táº¥t cáº£ experiments
- **Metrics history** Ä‘Æ°á»£c lÆ°u JSON format
- **TensorBoard** integration cho fine-tuning
- **Weights & Biases** support (optional)

### Log Files
```
outputs/logs/
â”œâ”€â”€ all_YYYYMMDD_HHMMSS.log          # Táº¥t cáº£ logs
â”œâ”€â”€ errors_YYYYMMDD_HHMMSS.log       # Chá»‰ errors
â”œâ”€â”€ experiments_YYYYMMDD_HHMMSS.log  # Experiment tracking
â””â”€â”€ experiment_[name]_YYYYMMDD.log   # Per-experiment logs
```

## ğŸš¦ Quy TrÃ¬nh Development

### 1. Setup vÃ  Validation
```bash
python scripts/setup_project.py
# Kiá»ƒm tra PROJECT_STATUS.json
```

### 2. Data Processing
```bash
python scripts/run_data_processing.py
```

### 3. Quick Testing vá»›i Prompting
```bash
# Test nhá» vá»›i 100 samples
python scripts/run_prompting.py --sample-size 100
```

### 4. Fine-tuning (trÃªn GPU)
```bash
# Báº¯t Ä‘áº§u vá»›i RoBERTa
python scripts/run_fine_tuning.py --model roberta

# Thá»­ nghiá»‡m advanced
python scripts/run_fine_tuning.py --model mistral --use-peft
```

### 5. Comparison vÃ  Analysis
```bash
python scripts/run_comparison.py
python scripts/generate_final_report.py
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **NLTK punkt_tab error**:
```bash
python -c "import nltk; nltk.download('punkt_tab')"
```

2. **GPU memory issues**:
- Giáº£m batch size trong config
- Enable gradient checkpointing
- Sá»­ dá»¥ng 4-bit quantization

3. **API rate limits**:
- Äiá»u chá»‰nh batch_size trong api_config.yaml
- Increase retry_delay

4. **Import errors**:
- Äáº£m báº£o virtual environment activated
- Check sys.path trong scripts

## ğŸ“š Code Structure Details

### Key Components

#### Data Processing
- `WebisClickbaitLoader`: Load vÃ  extract text features
- `SocialMediaTextCleaner`: LÃ m sáº¡ch vÄƒn báº£n chuyÃªn biá»‡t
- `LabelConverter`: Chuyá»ƒn Ä‘á»•i truthMean â†’ binary
- `StratifiedDataSplitter`: Chia dá»¯ liá»‡u cÃ³ stratification

#### Fine-tuning
- `ModelManager`: Quáº£n lÃ½ models vÃ  tokenizers
- `PEFTTrainer`: PEFT/LoRA training
- `UnslothTrainer`: Unsloth optimization
- `MetricsCalculator`: TÃ­nh toÃ¡n vÃ  tracking metrics

#### Prompting
- `PromptTemplateManager`: Quáº£n lÃ½ prompt templates
- `LLMClients`: API clients cho cÃ¡c providers
- `BatchEvaluator`: Evaluation batch processing
- `CostCalculator`: Tracking API costs

#### Utilities
- `LoggingUtils`: Centralized logging
- `ConfigManager`: Configuration management
- `GPUManager`: GPU utilities
- `FileManager`: File I/O helpers

## ğŸ¯ Expected Outcomes

### Performance Targets
- **Accuracy**: > 85% (so vá»›i 87.6% cá»§a winner 2017)
- **F1-score**: > 70% (so vá»›i 74.1% cá»§a winner 2017)
- **Speed**: < 100ms inference time cho production

### Deliverables
1. **Trained Models**: RoBERTa, Mistral, LLaMA fine-tuned
2. **Evaluation Results**: Comprehensive comparison
3. **Cost Analysis**: Detailed breakdown cho cáº£ approaches
4. **Recommendations**: Strategic recommendations
5. **Deployment Ready**: Production-ready pipeline

## ğŸ“– Next Steps

1. âœ… **HoÃ n táº¥t setup**: Cháº¡y `python scripts/setup_project.py`
2. â³ **Data processing**: Xá»­ lÃ½ vÃ  clean dá»¯ liá»‡u  
3. â³ **Prompting experiments**: Quick validation
4. â³ **ThuÃª GPU A5000**: Cho fine-tuning phase
5. â³ **Fine-tuning experiments**: Comprehensive training
6. â³ **Comparison vÃ  analysis**: Final evaluation
7. â³ **Report generation**: Documentation vÃ  recommendations

---

**ğŸ“§ Contact**: Äá»ƒ há»— trá»£ hoáº·c cÃ¢u há»i vá» implementation, vui lÃ²ng tham kháº£o logs trong `outputs/logs/` hoáº·c check `PROJECT_STATUS.json` Ä‘á»ƒ biáº¿t tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a dá»± Ã¡n. 